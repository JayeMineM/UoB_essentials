# -*- coding: utf-8 -*-
"""May2021ReSubmit_COS7045B_AML_CNNonCIFAR10_JMBOGBA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j6tkYiPi1jBwcuZe_G5BhObLLULUpAzm

# Convolutional Neural Network (**CNN**) on CIFAR-10 Dataset: **added VAT** (Virtual Adversarial Training)

# **Convolutional Neural Network (CNN) OVERVIEW**



###**Neural Network**






  ![Neural_Network_fish](https://www.python-course.eu/images/neural_network_fish.png) 





###**CNN**




  ![CNN_brain](https://www.deepcoredata.com/wp-content/uploads/2016/06/small_1420.png)

![CNN input image](https://images.squarespace-cdn.com/content/54856bade4b0c4cdfb17e3c0/1478984569132-6IM9DVIMXJ5FSE08FZT2/?content-type=image%2Fjpeg
)

##**Activation Layer**

● Used to increase non-linearity of the network without affecting receptive fields of conv layers

● Prefer ReLU, results in faster training

● LeakyReLU addresses the vanishing gradient problem

##**Pooling Layer**
● Convolutional layers provide activation maps.

● Pooling layer applies non-linear downsampling on activation maps.

● Pooling is aggressive (discard info); the trend is to use smaller filter size
and abandon pooling

![CNN Layers plan](https://stanford.edu/~shervine/teaching/cs-230/illustrations/architecture-cnn-en.jpeg?3b7fccd728e29dc619e1bd8022bf71cf)



![CNN input image](https://images.squarespace-cdn.com/content/54856bade4b0c4cdfb17e3c0/1478984569132-6IM9DVIMXJ5FSE08FZT2/?content-type=image%2Fjpeg
)


![CNN Layers Dimensions](https://miro.medium.com/max/770/1*kToStLowjokojIQ7pY2ynQ.jpeg)

##[**CIFAR-10 Dataset**](http://www.cs.toronto.edu/~kriz/cifar.html)

The CIFAR-10 and CIFAR-100 are labelled subsets of the [80 million tiny images](http://people.csail.mit.edu/torralba/tinyimages/) dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.

####**Overview**
The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

Here are the classes in the dataset, as well as 10 random images from each:
* **airplane** ![airplane](http://www.cs.toronto.edu/~kriz/cifar-10-sample/airplane4.png) 	& **automobile**![auto](http://www.cs.toronto.edu/~kriz/cifar-10-sample/automobile4.png)	& **bird**	![bird](http://www.cs.toronto.edu/~kriz/cifar-10-sample/bird6.png) ![hen](http://www.cs.toronto.edu/~kriz/cifar-10-sample/bird10.png)  & 	 **cat**	 ![cat](http://www.cs.toronto.edu/~kriz/cifar-10-sample/cat2.png) & 	**deer**	![deer](http://www.cs.toronto.edu/~kriz/cifar-10-sample/deer6.png)  	 	 	 	 	 	 	 	 	 
* **dog**	 	![dog](http://www.cs.toronto.edu/~kriz/cifar-10-sample/dog4.png) &  	 **frog** ![frog](http://www.cs.toronto.edu/~kriz/cifar-10-sample/frog1.png) 	 	 	 &		**horse**	 ![horse](http://www.cs.toronto.edu/~kriz/cifar-10-sample/horse2.png) 	 & **ship**	 	![ship](http://www.cs.toronto.edu/~kriz/cifar-10-sample/ship10.png)  	 	 &	 **truck**	 ![truck](http://www.cs.toronto.edu/~kriz/cifar-10-sample/truck5.png) 	 	 	 	 	 	 	 	 	 

The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. “Automobile” includes sedans, SUVs, things of that sort. “Truck” includes only big trucks. Neither includes pickup trucks.

**Download URL:** http://www.cs.toronto.edu/~kriz/cifar.html

---
For our experiment, CIFAR10 is downloaded with a one-hot code
```
cifar10.load_data()
```
as it is part of Keras bundled datasets. Explanatory variables and Target label of Training and Test sets are respectively extracted as (train_X, train_y), (test_X, test_y) .  A small range of records can then be plotted through a deined function as follows:
"""

!ls

"""##**Exploratory Data Analysis**

###**Useful libraries Import**
"""

#necessary libraries import
import sys
import keras
import tensorflow as tf
from tensorflow import keras

# Pandas and numpy for data manipulation
import pandas as pd
import numpy as np
np.random.seed(42)

# Matplotlib and seaborn for plotting
import plotly.express as px
import matplotlib.pyplot as plt 
#%matplotlib inline
import seaborn as sns

# Scipy helper functions
from scipy.stats import percentileofscore
from scipy import stats

"""##**Load Data**"""

###load
from keras.datasets import cifar10

def load_dataset():
  # Cifar-10 load dataset and split
  # (train_X, train_y), (test_X, test_y) = tf.keras.datasets.cifar10.load_data()
  (train_X, train_y), (test_X, test_y) =keras.datasets.cifar10.load_data()
  # summarize loaded dataset
  print('train_X=%s, train_y=%s' % (train_X.shape, train_y.shape))
  print('test_X=%s, test_y=%s' % (test_X.shape, test_y.shape))

  return train_X, train_y, test_X, test_y



train_X, train_y, test_X, test_y=load_dataset()

"""###**Data Structure Inspection**"""

train_y.shape

test_y.shape

train_y[:5]

train_y[0]

train_y[3][0]

"""###Reshaping label train_y an test_y 
The structure of train_y=**(50000, 1)** and test_y=**(10000, 1)** indicates and array of arrays (2-D array) and needs to be reshaped to a 1-D array by a one-hot code:

```
train_y=train_y[:,0]
test_y=test_y[:,0]
```
Otherwise, a segmentation of any of the data (train_y or test_y) is going to produce 20 classes, instead of the expected 10 labels, as 10 extra arrays of null values are strangely added...!!! WEIRD !!!

"""

train_y=train_y[:,0]
test_y=test_y[:,0]

train_y, train_y.shape, test_y, test_y.shape

"""### Inspecting train_X and test_X"""

train_X[:,:,-1].shape, train_X[:,-1].shape

i=0
train_X[:,:,i,:]
train_X[i] # i-th picture(image or pixels group).
train_X[i].shape

i,r=2,31
train_X[i][r] # r-th row of pixels of i-th picture(image)
train_X[i][r].shape

i,r,c,f=2,31,2,4
train_X[i][r][c:f].shape,train_X[i][r][c:f] # c to f-1_th column of r-th row of pixels of i-th picture(image).

i,r,c,p=2,31,2,2
train_X[i][r][c][p] # p-th channel value of c-th column of r-th row of pixels of i-th picture(image).

"""###Training Data (train_X & train_y) Conversion to Pandas DataFrame"""

train_X.shape

train_X4df=np.array(train_X).reshape(len(train_X),-1) # -1 is to flatten the image channels of pixels into 32*32*3=3072
train_X4df.shape

# now building a frame of 3072 columns
import pandas as pd
train_Xdf=pd.DataFrame(train_X4df)

train_Xdf.info()

train_Xdf.head()

train_Xdf.isnull().sum()

#label addition
train_Xdf['label']=train_y
train_df=train_Xdf
train_df.head()

train_df.info()

train_df.isnull().sum().sum()

# dataframe columns view
train_df.columns

"""###Variables Correlation"""

train_df.describe()

#sns.heatmap(train_df.corr(), ); #annot=True

"""###Distribution of Label"""

train_df.label.value_counts()

"""###Retrieving Classes (label names)
To begin with, A function label_display is first defined to retrieve random images of objects according to their respective label ID values [ from 0 to 9] and to be able to confirm, with human eyes natural power and brain coordination that label names are correctly assigned to pictures. An initial run of the defined function can be seen in below 
"""

# set the matplotlib backend so figures can be saved in the background
#import matplotlib                  # (I_line2)
#matplotlib.use("Agg") 
             # (I_line3)
# import the necessary packages
from sklearn.metrics import classification_report  # (I_line7)
#from keras.optimizers import SGD                 # (I_line8)
from keras.utils import np_utils
#from keras import backend as K                # (I_line11)
from imutils import build_montages           # (I_line12)
#import matplotlib.pyplot as plt            # (I_line13)
import numpy as np
import cv2                               # (I_line15)

from tqdm import tqdm #jayAdd for progress bar taqaduma('I love U so much')

#@title jayform

def call__imgNumJayForm(): #@title jayForm
  #@markdown Please INPUT the amount of images (no more than 24) to randomly display:
  imgNum=24 #@param{type:'integer'}
  #print(imgNum)
  return imgNum

call__imgNumJayForm()

def label_display(data, target):  
  #trying to view images of imgNum number of randomly select items  
  imgNum=int(input('Please INPUT the amount of images (no more than 24) to randomly display:'))
  
  #imgNum= 0 #@param{type:'integer'}
  if imgNum>24:    
    print('Large number exceeding 24...function closing...sorry!')
    
  else:
    labelNames=[] #name to file as per class value when recognized
    labelNames=['airplane', 'automobile','bird','cat','deer','dog', 'frog', 'horse', 'ship', 'truck'] 
    
    images=[]          
    for i in tqdm(np.random.choice(np.arange(0, len(target)), size=(imgNum,))):

      labelIDtext=str(target[i]) # cast to string to avoid...SystemError:
    # <built-in function putText> returned NULL without setting an error

      label=labelNames[target[i]] 
    # May uncomment this code to display items names (labelNames)...and follow instruction at (LINEprintNAMES) further down

  #we are using "channels_last" ordering
      image=data[i].astype('uint8')

  # initialize the text label color as green (correct)		
      color = (0, 255, 0)      # (I_line108)

  # merge the channels into one image and resize the image from
	# 32x32 to 96x96 so we can better see it and then draw the
	# predicted label on the image

  #image = cv2.merge([image]*3)      #this code is not required as color channels are already 3
      image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR) 
      cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.50,color, 2) 
      # May replace 'labelIDtext' parameter above with 'label' to display names.# or put 'labelIDtext' back at 'label' (LINEprintNAME)

  # add the image to our list of output images
      images.append(image)                 # (I_line123)
 # construct the montage for the images 
      canvasWidth=0 # initializing the width of the canvas, while the height is set to 4
      #canvasHeight=0 # initializing the height of the canvas, while the width is set to 10
      if imgNum%4==0:
        canvasWidth=imgNum//4
        #canvasHeight=imgNum//10
      else:
        canvasWidth=imgNum//4 +1
        #canvasHeight=imgNum//10 +1

      montage = build_montages(images, (96, 96), (canvasWidth, 4))[0]  # (I_line126)
      #montage = build_montages(images, (96, 96), (canvasHeight, 10))[0] 
  # show the output montage
           # cv2.imshow("Fashion MNIST", montage)  #jayNote: deprecated class
    from google.colab.patches import cv2_imshow
    cv2_imshow(montage)                # (I_line129)
    cv2.waitKey(0)                    # (I_line130)

test_y[1]

label_display(test_X,test_y)

"""An initial run of above created function ***label_display*** allows us to see that:
labelID_**3** is **cat** & labelID_**2** is **bird** & labelID_**1** is **automobile** & labelID_**5** is **dog**...
and we can re-run the function as many times as we can clearly identify all classes representative images and IDs.
Hence, it can further be seen after recurrent runs that:
... labelID_**0** is airplane & LabelID_**4** is **deer** & labelID_**6** is **frog** & labelID_**7** is **horse** & labelID_**8** is **ship** & labelID_**9** is **truck**.

Our observation is therefore in line with the dataset classes description and label names can be orderly listed as:

```
LabelNames=['airplane', 'automobile','bird','cat','deer','dog', 'frog', 'horse', 'ship', 'truck']
```


```
labelIDtext=str(target[i]) # cast to string to avoid...SystemError:
    # <built-in function putText> returned NULL without setting an error

      #label=labelNames[target[i]] # Uncomment this line to display names instead of labelID
```

Finally replacing *labelIDtext* parameter with ***label*** in method **cv2.putText** in below portion code of our classes_display function will therefore allow us to display object name instead of their labelID.
```
#image = cv2.merge([image]*3)      #this code is not required as color channels are already 3
      image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR) 
      cv2.putText(image, labelIDtext, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.50,color, 2) 
      # May replace 'labelIDtext' parameter above with 'label' to display names.
```

**Making Dictionary assign label name to labels**
"""

classes={0 :'airplane', 1 :'automobile', 2 :'bird', 3 :'cat', 4 :'deer', 5 :'dog', 
         6 : 'frog', 7 :'horse', 8 :'ship', 9 :'truck'}

classes[1]

classes.keys()

"""###Value Counts for **label**(categorical) Column ¶"""

df= train_df[['label']]
#labelDict={v:k for k,v in classes.items()}

df

classes.items()
#labelDict
#df.replace({'label':labelDict}, inplace=True)



df['labelName'] = df['label'].apply(lambda x: classes[x])
train_df['labelName'] = train_df['label'].apply(lambda x: classes[x])

train_df

df

df.labelName.value_counts()

# Print the value counts for categorical columns
print('\nColumn Name:','label',)
print(train_df['label'].value_counts())

train_X.shape

"""##**Plot the dataset...**

### ...by Viewing few images
"""

# plot first few images from either train_X or test_X
def plot_fewImg(data,n):
  plt.figure(figsize=(6, 6))
  for i in range(n):
	  # define subplot
	  plt.subplot(n//3,3,1 + i)
    # plot raw pixel data
	  plt.imshow(data[i])
  # show the figure 
  plt.show()

df.labelName.value_counts().keys()

df.labelName.value_counts().values

fig=px.bar(x=df.labelName.value_counts().keys(), y=df.labelName.value_counts().values)
fig.show()

plot_fewImg(train_X,9)



"""...by Central pixel channel value"""

np.unique(train_df.labelName.values)

train_df.columns

train_df.iloc[:,1536]



#fig=px.scatter(test_idArray, testX[:,0,11, 2], color=classes.keys)
fig=px.scatter(train_df, x=train_df.index, y=train_df.iloc[:,1536].values, color='label', hover_data=['labelName'])
fig.show()

"""# **Convolutional Neural Network (CNN) Construction**

###Relevant Libraries import
"""

from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

"""##**Developing a Baseline Model**

###**Baseline: 3 VGG Blocks**
The define_model() function for three VGG blocks is listed below.
"""

# Baseline version of define_model()
def baseline_CNN_3VGG():

	model =keras.Sequential(name='baselineCNN3VGG') # Our model  is initialized using the Sequential  API
  
	# first set of CONV => RELU => POOL layers
	#inputs=keras.Input(shape=(32, 32, 3))
	model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32,32,3))) #input_dim=3072
	model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(keras.layers.MaxPooling2D((2, 2)))
	
	 # second set of CONV => RELU => POOL layers
	model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(keras.layers.MaxPooling2D((2, 2)))
	
	 # third set of CONV => RELU => POOL layers
	model.add(keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(keras.layers.MaxPooling2D((2, 2)))
 
 	#first (and only) set of FC (Final Coding) => RELU layers
	model.add(keras.layers.Flatten()) # the output of the preceding MaxPooling2D  layer and flatten it into a single vector.
	model.add(keras.layers.Dense(512, activation='relu', kernel_initializer='he_uniform')) # Our fully-connected layer contains 128 nodes
	model.add(keras.layers.Dense(10, activation='softmax')) # another fully-connected layer, but this one is special; num nodes= num classes
  
	# compile model
	#opt = SGD(lr=0.001, momentum=0.9)
	opt=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)
	model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

	return model

JMmodel=baseline_CNN_3VGG()
JMmodel.summary()

"""![](https://miro.medium.com/max/761/1*r1c1C2RY8tkR_SvdV6aHsw.png)
**Table 1. ResNets architectures for ImageNet**

Bibliography
[1] K. He, X. Zhang, S. Ren and J. Sun, “Deep Residual Learning for Image Recognition,” in CVPR, 2016.
"""

print("Number of weights after calling the model:", len(JMmodel.weights))

"""##**Model Evaluation Test Harness**
The CIFAR-10 dataset can be a useful starting point for developing and practicing a methodology for solving image classification problems using convolutional neural networks.


The design of the test harness is modular, and we can develop a separate function for each piece. This allows a given aspect of the test harness to be modified or interchanged, if we desire, separately from the rest.

We can develop this test harness with five key elements. They are the loading of the dataset, the preparation of the dataset, the definition of the model, the evaluation of the model, and the presentation of results.

####*Step_1:* ***Load*** & ***Partition*** (pSplit %) & **Categorical**
"""

#partition
def pSplit_partition(train_X, train_y):
  pSplit=int(input('Please PROVIDE percentage of Reduction for a total of {} Training records:  '.format(len(train_X))))
  trainSel=np.random.choice(np.arange(0,len(train_X)), size=len(train_X)*pSplit//100)
  trainX, trainY=train_X[trainSel], train_y[trainSel]
  return trainX, trainY

trainX, trainY=pSplit_partition(train_X, train_y)
trainX.shape, trainY.shape

"""**to_catego**

  For usability sake , let's define a function to transform the target values(labels) to categorical
"""

from keras.utils import to_categorical
def to_catego(train_y,test_y):
  trainY=to_categorical(train_y)
  testY=to_categorical(test_y)
  print('trainX=%s, trainY=%s' % (trainX.shape, trainY.shape)) # summarize partition-category
  print('test_X=%s, testY=%s' % (test_X.shape, testY.shape))

  return trainY, testY

trainY, testY=to_catego(trainY,test_y)

"""Outputs observation"""

trainX
trainX.shape, test_X.shape

trainY
trainY.shape, trainY[2]

testY
testY.shape

"""####*Step_2:* ***prepare pixel-data***

"""

# a Regularistion step
def prep_pixels(train, test):
	# convert from integers to floats
	train_norm = train.astype('float32')
	test_norm = test.astype('float32')
	# normalize to range 0-1
	train_norm = train_norm / 255.0
	test_norm = test_norm / 255.0
	# return normalized images
	return train_norm, test_norm

# prepare pixel data # ..when needed...
trainXprep, testXprep = prep_pixels(trainX, test_X)

trainXprep
trainXprep.shape

testXprep
testXprep.shape

trainY.shape

"""*Step_3:* ***launch the defined model**"""

trainXprep.shape

trainY.dtype

trainY.shape ##to crossCheck

trainY.dtype,  trainY

baseline_CNN_3VGG()



testXprep.shape, test_X.shape

"""###Test-Harness 6 Paramount STEPS
As a **prerequisite**, we have got to:
* *make sure relevant libraries (associated to functions and variables) are imported (as seen in following described steps)*
* *define the experimented model [e.g baseline_CNN_3VGG()] and run the relevant notebook cell (as above) contening the model function*
* *run relevant notebook cells contening each of the 3 functions below* 


step_1:

  a)**load_dataset & split** 

  b) further partition **pSplit**  trainRecords for more epochs (if not enough time to wait...)

  c) **to_catego** target variables to Category
 
 ###load
```
from keras.datasets import cifar10

def load_dataset():
  # Cifar-10 load dataset
 
  (train_X, train_y), (test_X, test_y) = cifar10.load_data()

  # summarize loaded dataset
  print('train_X=%s, train_y=%s' % (train_X.shape, train_y.shape))
  print('test_X=%s, test_y=%s' % (test_X.shape, test_y.shape))

  return train_X, train_y, test_X, test_y

```
###partition
```
from keras.utils import to_categorical

def pSplit_partition():
  pSplit=input('please provide percentage of Reduction for a total of {} Training records '.format(len(train_X))

  trainSel=np.random.choice(np.arange(0,len(train_X)), size=len(train_X)*pSplit//100)
  trainX, trainY=train_X[trainSel], train_y[trainSel]
  return trainX, trainY
```
**target2category**
```
def to_catego(train_y,test_y):
	# one hot encode target values

	trainY = to_categorical(train_y)
	testY = to_categorical(test_y)
	return trainY, testY

  # summarize partition-category
  print('trainX=%s, trainY=%s' % (trainX.shape, trainY.shape))
  print('test_X=%s, testY=%s' % (test_X.shape, testY.shape))
```

action-1....
```
train_X, train_y, test_X, test_y=load_dataset()
trainX, trainY=pSplit_partition()

trainY, testY= to_catego(train_y,test_y) ...bug!
trainYcateg, testYcateg= to_catego(trainY,test_y) ...potential correction
```

Step_2: **prepare pixel-data**

```
def prep_pixels(train, test):
	# convert from integers to floats
	train_norm = train.astype('float32')
	test_norm = test.astype('float32')
	# normalize to range 0-1
	train_norm = train_norm / 255.0
	test_norm = test_norm / 255.0
	# return normalized images
	return train_norm, test_norm
 
 ```
action-2....

```
 trainXprep, testXprep = prep_pixels(trainX, test_X)

 # summarize pixel prepa
  print('trainXprep=%s, testXprep=%s' % (trainXprep.shape, testXprep.shape))
```

Step_3: **launch the defined model**

```
def model_launch():
  model=baseline_CNN_3VGG() # !!!...to UPDATE with Relevant Model... !!!
  model=model
  return model
```
Step_4: **fit model**

```
def fit_model(modelJay, trainXprep, trainY):
  
  try:
    eNum=int(input('Please INPUT the desired number of epochs:'))
  except ValueError:
    print('invalid entry!!...process aborted...sorry...!')
    #exit
  #model=modelJay()#heavy...!!
  print(modelJay().name)
  
  hist = modelJay().fit(trainXprep, trainY, epochs=eNum, batch_size=64, validation_split=0.3, verbose=1,)
# validation_split=0.1means we use 10% of training data as the validation data
# epochs is the number of training loops we will do. 
# one epoch will expose all of our training data once to the network. 
# more epochs means the network will know better about our data.
# and the result is...

  return eNum,hist

```

action-3&4
```
model_launch(model)
hist=fit_model()
```

Step_5: learning curves  & action-6...
```
from matplotlib import pyplot
summarize_diagnostics(history)
```

Step_6: view predictions
```
view_prediction()
```

Step_7: view Report 
```
view_report()
```

###**Steps Resumption....**

####Step_4: **Fit model**...
"""



"""
```
from tqdm.keras import TQDMNotebookCallback
...
model.fit(..., verbose=0, callbacks=[TQDMNOtebookCallback(verbose=2)])
```

**This turns off keras' progress (verbose=0), and uses tqdm instead**. 

For the TqdmCallback(verbose=...)
* **2** means ***separate progressbars for epochs and batches.***

* **1** means ***clear batch bars when done***. 
 
* **0** means ***only show epochs (never show batch bars)***."""

!pip install keras_tqdm # please uncomment adjacent code if dependency keras_tqdm not installed yet.

#from keras_tqdm import TQDMNotebookCallback

import tensorflow as tf
from tensorflow import keras

class CustomCallback(keras.callbacks.Callback):
    def on_train_begin(self, logs=None):
        keys = list(logs.keys())
        print("Starting training; got log keys: {}".format(keys))

    def on_train_end(self, logs=None):
        keys = list(logs.keys())
        print("Stop training; got log keys: {}".format(keys))
  
    def on_test_begin(self, logs=None):
        keys = list(logs.keys())
        print("Start testing; got log keys: {}".format(keys))

    def on_test_end(self, logs=None):
        keys = list(logs.keys())
        print("Stop testing; got log keys: {}".format(keys))

    def on_predict_begin(self, logs=None):
        keys = list(logs.keys())
        print("Start predicting; got log keys: {}".format(keys))

    def on_predict_end(self, logs=None):
        keys = list(logs.keys())
        print("Stop predicting; got log keys: {}".format(keys))

val_split=0.3
try:
  eNum=int(input('Please INPUT the desired number of epochs:'))
except ValueError:
  print('invalid entry!!...process aborted...sorry...!')
    #exit
JMmodel=baseline_CNN_3VGG
print("Number of weights on Model call:", len(JMmodel().weights))
hist = JMmodel().fit(trainX, trainY, epochs=eNum, batch_size=64, validation_split=val_split, verbose=1, 
                 #callbacks=[CustomCallback()]
                  ) 
# validation_split=0.1 means we use 10% of training data as the validation data
# epochs is the number of training loops we will do. 
# one epoch will expose all of our training data once to the network. 
# more epochs means the network will know better about our data.
# and the result is...

JMmodel().summary()

"""The **validation accuracy ```val_accuracy```** is described as a function of the number of training steps. """

print(hist.history)

print(hist.history['loss'])

testY.argmax(axis=1), testY

trainXprep, testXprep = prep_pixels(trainX, test_X)
 # summarize pixel prepa
print('trainXprep=%s, testXprep=%s' % (trainXprep.shape, testXprep.shape))

def fit_model_NORMALised(modelJay, trainXprep, trainY):
  
  try:
    eNum=int(input('Please INPUT the desired number of epochs:'))
  except ValueError:
    print('invalid entry!!...process aborted...sorry...!')
    #exit
  #model=modelJay()#heavy...!!
  print(modelJay().name)
  
  hist = modelJay().fit(trainXprep, trainY, epochs=eNum, batch_size=64, validation_split=0.3, verbose=1,)
# validation_split=0.1means we use 10% of training data as the validation data
# epochs is the number of training loops we will do. 
# one epoch will expose all of our training data once to the network. 
# more epochs means the network will know better about our data.
# and the result is...

  return eNum,hist

"""```
trainYcateg, testYcateg= to_catego(trainY,test_y) ...potential correction
```

```
def fit_model(modelJay, train_X, trainY):
  
  try:
    eNum=int(input('Please INPUT the desired number of epochs:'))
  except ValueError:
    print('invalid entry!!...process aborted...sorry...!')
    #exit
  #model=modelJay()#heavy...!!
  print(modelJay().name)
  
  hist = modelJay().fit(train_X, trainY, epochs=eNum, batch_size=64, validation_split=0.3, verbose=1,)
  # validation_split=0.1means we use 10% of training data as the validation data
  # epochs is the number of training loops we will do. 
  # one epoch will expose all of our training data once to the network. 
  # more epochs means the network will know better about our data.
  # and the result is...

  return eNum,hist
```
"""



def fit_model(modelJay, train_X, trainY):
  
  try:
    eNum=int(input('Please INPUT the desired number of epochs:'))
  except ValueError:
    print('invalid entry!!...process aborted...sorry...!')
    #exit
  #model=modelJay()#heavy...!!
  print(modelJay().name)
  
  hist = modelJay().fit(train_X, trainY, epochs=eNum, batch_size=64, validation_split=0.3, verbose=1,)
  # validation_split=0.1means we use 10% of training data as the validation data
  # epochs is the number of training loops we will do. 
  # one epoch will expose all of our training data once to the network. 
  # more epochs means the network will know better about our data.
  # and the result is...

  return eNum,hist

trainX.shape, trainY.shape

modelJay=baseline_CNN_3VGG
eNum, hist=fit_model(modelJay,trainX, trainY)
print(hist.history)

"""####Step_5: **learning curves** ...
```
from matplotlib import pyplot
summarize_diagnostics(history)
```
"""

#hist.history['train_loss'] # to fail...as... column 'train_loss' updated to 'loss' [04May2021_JayDiscovery]
#hist.history['loss']

#len(trainXprep), val_split, len(trainXprep)*val_split
len(trainX), val_split, len(trainX)*val_split

print('val_split is : %.3f ' %val_split)
print('trainXprep is ', len(trainXprep))
print('Validation batch size : %d ' %(len(trainXprep)*val_split))
print('Train batch size : %d ' %(len(trainXprep)*(1-val_split)))

print('val_split is : %.3f ' %val_split)
print('trainXprep is ', len(trainX))
print('Validation batch size : %d ' %(len(trainX)*val_split))
print('Train batch size : %d ' %(len(trainX)*(1-val_split)))

def summarize_diagnostics_NORMALised(myModel, eNum,hist):
    
    plt.figure(figsize=(18,12))

    # plot loss
    pyplot.subplot(221)
    pyplot.title('model %s Cross Entropy Loss'%myModel().name)
    pyplot.plot(hist.history['loss'], color='blue', label='Train')
    pyplot.plot(hist.history['val_loss'], color='orange', label='Validation')
    plt.legend()
    print('eNum= ', eNum)
    #print('CrossEntropLoss ticks range is ',[i for i in range(eNum +1)])
    plt.xticks([i for i in range(eNum+1)])
    plt.xlabel('epochs')
    plt.ylabel('loss')

    # plot accuracy
    pyplot.subplot(222)
    pyplot.title('model %s Classification Accuracy'%myModel().name)
    pyplot.plot(hist.history['accuracy'], color='blue', label='Train')
    pyplot.plot(hist.history['val_accuracy'], color='orange', label='Validation')
    plt.legend()
    print('val_split is : %.3f ' %val_split)
    print('trainXprep is ', len(trainXprep))
    print('Validation batch size : %d ' %(len(trainXprep)*val_split))
    print('Train batch size : %d ' %(len(trainXprep)*(1-val_split)))
   
    #print('Accuracy ticks range is ',[i for i in range(eNum+1)])
    plt.xticks([i for i in range(eNum+1)])
    plt.xlabel('epochs')
    plt.ylabel('accuracy')
    plt.show()
    
    # save plot to file
    #filename = sys.argv[0].split('/')[-1]
    #pyplot.savefig(filename + '_plot.png')
    #pyplot.close()

def summarize_diagnostics(myModel, eNum, hist):
    
    plt.figure(figsize=(18,12))

    # plot loss
    pyplot.subplot(221)
    pyplot.title('model %s Cross Entropy Loss'%myModel().name)
    pyplot.plot(hist.history['loss'], color='blue', label='Train')
    pyplot.plot(hist.history['val_loss'], color='orange', label='Validation')
    plt.legend()
    print('eNum= ', eNum)
    #print('CrossEntropLoss ticks range is ',[i for i in range(eNum +1)])
    plt.xticks([i for i in range(eNum+1)])
    plt.xlabel('epochs')
    plt.ylabel('loss')

    # plot accuracy
    pyplot.subplot(222)
    pyplot.title('model %s Classification Accuracy'%myModel().name)
    pyplot.plot(hist.history['accuracy'], color='blue', label='Train')
    pyplot.plot(hist.history['val_accuracy'], color='orange', label='Validation')
    plt.legend()
    print('val_split is : %.3f ' %val_split)
    print('trainXprep is ', len(trainX))
    print('Validation batch size : %d ' %(len(trainX)*val_split))
    print('Train batch size : %d ' %(len(trainX)*(1-val_split)))
   
    #print('Accuracy ticks range is ',[i for i in range(eNum+1)])
    plt.xticks([i for i in range(eNum+1)])
    plt.xlabel('epochs')
    plt.ylabel('accuracy')
    plt.show()
    
    # save plot to file
    #filename = sys.argv[0].split('/')[-1]
    #pyplot.savefig(filename + '_plot.png')
    #pyplot.close()

# learning curves
#import sys
#import numpy as np
from matplotlib import pyplot
summarize_diagnostics(JMmodel,eNum,hist)

"""####*Step_6:* ***Predictions***

**UnTrained Model PREDICTIONs** (...on NORMALised & Plain pixels)

REMINDER
```
#testY=to_categorical(data)
testY_revCat=np.argmax(testY,axis=1) # Reverse of to_categorical
testY_revCat

```
"""

#pred.argmax(-1)# or pred.argmax(axis=1) #the reverse of to_categorical

testY

#testY=to_categorical(data)
testY_revCat=np.argmax(testY,axis=1) # Reverse of to_categorical
testY_revCat

testY.shape, testY_revCat.shape

#label_display(test_X,testY_revCat) #...Fix this if time...

# Untrained Model PREDICTION on NORMALised pixels # Trigger Datatype Warning Issues...!!!...Avoid for NOW...!!!
from sklearn.metrics import accuracy_score
prep_y_pred  = JMmodel().predict(testXprep).argmax(-1)
print("Test accuracy..." , accuracy_score(testY_revCat , prep_y_pred ))
print('prep_y_pred ...', prep_y_pred)

# Untrained Model PREDICTION on Plain pixels
from sklearn.metrics import accuracy_score
#Reminder # trainXprep, testXprep = prep_pixels(trainX, test_X)
y_pred  = JMmodel().predict(test_X).argmax(-1)
print("Test accuracy..." , accuracy_score(testY_revCat , y_pred ))
print('y_pred ...', y_pred)

set(prep_y_pred), set(y_pred) #more classes predicted in prep...to examine!!!

"""**sample Prediction**

REMINDER

```
#testY=to_categorical(data)
testY_revCat=np.argmax(testY,axis=1) # Reverse of to_categorical
testY_revCat
```

```
testY.shape, testY_revCat.shape
```

```
# Untrained Model PREDICTION on NORMALised pixels # Trigger Datatype Warning Issues...!!!...Avoid for NOW...!!!
from sklearn.metrics import accuracy_score
prep_y_pred  = JMmodel().predict(testXprep).argmax(-1)
print("Test accuracy..." , accuracy_score(testY_revCat , prep_y_pred ))
print('prep_y_pred ...', prep_y_pred)
```

```
# Untrained Model PREDICTION on Plain pixels
from sklearn.metrics import accuracy_score
y_pred  = JMmodel().predict(test_X).argmax(-1)
print("Test accuracy..." , accuracy_score(testY_revCat , y_pred ))
print('y_pred ...', y_pred)
```

```
set(prep_y_pred), set(y_pred)
```
"""

i=0
modelJoem=baseline_CNN_3VGG
#Single prediction
probs = modelJoem().predict(test_X[np.newaxis, i]) 
probs

test_X[np.newaxis, i].shape
probs.shape

#mass prediction
y_pred_list  = modelJoem().predict(test_X).argmax(-1)
y_pred_list.shape

#test_X[np.newaxis, i]
probs = modelJoem().predict(test_X[np.newaxis, i]) 
probs

prediction = probs.argmax(axis=1)  
prediction

#label = labelNames[prediction[0]]
label=classes[prediction[0]] # prediction is a single array ... and ... prediction[0] to retrieve the integer
label

test_X[i][0].shape

np.array(test_X[i]).shape

from keras import backend as K
K.image_data_format()

def view_prediction_NORMALised(modelJoem,testXprep,testY):
  from keras import backend as K
  from tqdm import tqdm #jayAdd for progress bar taqaduma('I love U so much')

  #trying to view predicted names of randomly selected images from data
  imgNum=int(input('Please INPUT the amount of images for prediction (no more than 60) to randomly display:'))
  if imgNum>60:    
    print('Large number exceeding 60...function closing...sorry!')

  else:
    # initialize our list of output images
    images = []
    #jayAdd for evaluation metrics
    testYtrack=[] 
    predsTrack=[]
    failure=0
    # randomly select a few testing items    
                          # (I_line92)
    
    for i in tqdm(np.random.choice(np.arange(0, len(testY)), size=(imgNum,))):
      # classify the object  # (I_line94-96) 
      probs = modelJoem().predict(testXprep[np.newaxis, i])  
      prediction = probs.argmax(axis=1)  
      #label = labelNames[prediction[0]]
      label=classes[prediction[0]]

  # extract the image from the testData if using "channels_first"
	# ordering # (I_line100-105)
      if (K.image_data_format() == "channels_first"):
        image = (testXprep[i][0] * 255).astype("uint8")
    
       # otherwise we are using "channels_last" ordering
      else:
        image = (testXprep[i] * 255).astype("uint8")

    # initialize the text label color as green (correct)		
      color = (0, 255, 0)      # (I_line108)

    # otherwise, the class label prediction is incorrect
      if prediction[0]!= np.argmax(testY[i]):
        color=(0,0,255)           # (I_line112)
        failure+=1
      # merge the channels into one image and resize the image from
    	# 32x32 to 96x96 so we can better see it and then draw the
	    # predicted label on the image

      label_str=str(classes[prediction[0]])
      #label_str=str(labelNames[prediction[0]]) # cast to string to avoid...SystemError:
      # <built-in function putText> returned NULL without setting an error
  
      image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)  # (I_line118)
      #cv2.putText(image, labelNames, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,color, 2) # (I_line119)
      cv2.putText(image, label_str, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.50,color, 2) 
      # add the image to our list of output images
      images.append(image)                 # (I_line123)
 
      #JayAdd: test data and prediction tracking
      predsTrack.append(prediction[0])
      testYtrack.append(np.argmax(testY[i]))      
      success=imgNum-failure
      successRate=(imgNum-failure)*100/imgNum

     # construct the montage for the images 
      canvasWidth=0 # initializing the width of the canvas, while the height is set to 4
      if imgNum%6==0:
        canvasWidth=imgNum//6
      else:
        canvasWidth=imgNum//6 +1

      montage = build_montages(images, (96, 96), (canvasWidth, 6))[0]  # (I_line126)


    # show the output montage
    print('Successful Guess in GREEN & Failed guess in RED...')
    print(' ...GOOD guess: {} ...Bad Guess: {}...with a success rate of: {:.2f}%'.format(success,failure,successRate))
    from google.colab.patches import cv2_imshow
    cv2_imshow(montage)                # (I_line129)
    cv2.waitKey(0)                    # (I_line130)
    print('predsTrack is ...',np.array(predsTrack),'\n','testYtrack is ...', np.array(testYtrack)) #Beware of Indentation causing eternal loop for CRASH...!!!
  return np.array(predsTrack), np.array(testYtrack)



test_X.shape #this a Confirmed POWERFUL Numpy

probs = modelJoem().predict(test_X[np.newaxis, i]) 
probs

def view_prediction(modelJoem,test_X,testY):
  from keras import backend as K
  from tqdm import tqdm #jayAdd for progress bar taqaduma('I love U so much')

  #trying to view predicted names of randomly selected images from data
  imgNum=int(input('Please INPUT the amount of images for prediction (no more than 60) to randomly display:'))
  if imgNum>60:    
    print('Large number exceeding 60...function closing...sorry!')

  else:
    # initialize our list of output images
    images = []
    #jayAdd for evaluation metrics
    testYtrack=[] 
    predsTrack=[]
    failure=0
    # randomly select a few testing items  
    
    for i in tqdm(np.random.choice(np.arange(0, len(testY)), size=(imgNum,))):
      # classify the object  
      probs = modelJoem().predict(test_X[np.newaxis, i])  
      prediction = probs.argmax(axis=1)  
      #label = labelNames[prediction[0]]
      label=classes[prediction[0]]

  # extract the image from the testData if using "channels_first"
	# ordering # (I_line100-105)
      if (K.image_data_format() == "channels_first"):
        #image = (testXprep[i][0] * 255).astype("uint8") # NA..as NO Normalisation made!
        image = (test_X[i][0]).astype("uint8")
    
       # otherwise we are using "channels_last" ordering
      else:
        #image = (testXprep[i] * 255).astype("uint8") # NA ... as NO Normalisation made!
        image = (test_X[i]).astype("uint8")

    # initialize the text label color as green (correct)		
      color = (0, 255, 0)      # (I_line108)

    # otherwise, the class label prediction is incorrect
      if prediction[0]!= np.argmax(testY[i]):
        color=(0,0,255)           # (I_line112)
        failure+=1
      # merge the channels into one image and resize the image from
    	# 32x32 to 96x96 so we can better see it and then draw the
	    # predicted label on the image

      label_str=str(classes[prediction[0]])
      #label_str=str(labelNames[prediction[0]]) # cast to string to avoid...SystemError:
      # <built-in function putText> returned NULL without setting an error
  
      image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)  # (I_line118)
      #cv2.putText(image, labelNames, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,color, 2) # (I_line119)
      cv2.putText(image, label_str, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.50,color, 2) 
      # add the image to our list of output images
      images.append(image)                 # (I_line123)
 
      #JayAdd: test data and prediction tracking
      predsTrack.append(prediction[0])
      testYtrack.append(np.argmax(testY[i]))      
      success=imgNum-failure
      successRate=(imgNum-failure)*100/imgNum

     # construct the montage for the images 
      canvasWidth=0 # initializing the width of the canvas, while the height is set to 4
      if imgNum%6==0:
        canvasWidth=imgNum//6
      else:
        canvasWidth=imgNum//6 +1

      montage = build_montages(images, (96, 96), (canvasWidth, 6))[0] 


    # show the output montage
    print('Successful Guess in GREEN & Failed guess in RED...')
    print(' ...GOOD guess: {} ...Bad Guess: {}...with a success rate of: {:.2f}%'.format(success,failure,successRate))
    from google.colab.patches import cv2_imshow
    cv2_imshow(montage)               
    cv2.waitKey(0)             
    print('predsTrack is ...',np.array(predsTrack),'\n','testYtrack is ...', np.array(testYtrack)) #Beware of Indentation causing eternal loop for CRASH...!!!
  return np.array(predsTrack), np.array(testYtrack)

testXprep.shape, test_X.shape, testY.shape

#UNtrained model on NORMALised test_X
JMmodel=baseline_CNN_3VGG
view_prediction_NORMALised(JMmodel, testXprep, testY) #NORMALised test_X

JMmodel

#UNtrained model on PLAIN test_X
JMmodel=baseline_CNN_3VGG
#view_prediction(JMmodel, testXprep, testY) #NORMALised test_X
view_prediction(JMmodel, test_X, testY)

#UNtrained model on NORMALised Powerfully NUMPYed test_X
JMmodel=baseline_CNN_3VGG
#view_prediction(JMmodel, testXprep, testY) #
view_prediction_NORMALised(JMmodel, np.array(testXprep), testY) #NORMALised test_X ..with POWERFUL Numpy np.array... improving result by almost 100%!!!

#UNtrained model on PLAIN Powerfully NUMPYed test_X
JMmodel=baseline_CNN_3VGG
#view_prediction(JMmodel, testXprep, testY) #NORMALised test_X
view_prediction(JMmodel, np.array(test_X), testY) #Plain test_X ..with POWERFUL Numpy np.array... improving result by almost 100%!!!

"""REMINDER
```
classes={0 :'airplane', 1 :'automobile', 2 :'bird', 3 :'cat', 4 :'deer', 5 :'dog', 
         6 : 'frog', 7 :'horse', 8 :'ship', 9 :'truck'}
```
"""

label=classes[prediction[0]]
label

np_predsTrack, testYtrack=view_prediction(modelJoem,test_X,testY)

testY

np_predsTrack

testYtrack

#HERE....
#classification_report(y_true, y_pred, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')
#y_true is ground-truth from Reversed_catego testY & y_pred as predictionList
label=classes[prediction[0]]
labelNames=['airplane', 'automobile','bird','cat','deer','dog', 'frog', 'horse', 'ship', 'truck']
print(classification_report(testYtrack,np_predsTrack, target_names=labelNames))

"""REMINDER
```
i=0
modelJoem=baseline_CNN_3VGG
```
   Single prediction
``` 
test_X[np.newaxis, i].shape
probs = modelJoem().predict(test_X[np.newaxis, i])  
probs.shape  
```
```
prediction = probs.argmax(axis=1)  
prediction
```
```
  #label = labelNames[prediction[0]]
label=classes[prediction[0]] # prediction is a single array ... and ... prediction[0] to retrieve the integer
label
```

Mass prediction
```
y_pred_list  = modelJoem().predict(test_X).argmax(-1)
y_pred_list.shape
```



"""

#y_pred_track, testYtrack=view_prediction(modelJoem,test_X,testY)

"""REMINDER
```
def fit_model(modelJay, train_X, trainY):
  
  try:
    eNum=int(input('Please INPUT the desired number of epochs:'))
  
  [...]

  return eNum,hist
```
"""

#REMINDERs
#eNum,hist=fit_model(modelJay, train_X, trainY)
#modelJoem=baseline_CNN_3VGG
eNum_Joem, hist_Joem = fit_model(modelJoem, trainX, trainY)
# y_pred_track, testYtrack=view_prediction(modelJoem,testX,testY)
#def view_report(testY,eNum,hist,y_pred_track, testYtrack):

y_pred_track_Joem, testYtrack_Joem=view_prediction(modelJoem,test_X,testY)



"""# Jay TEST HARNESS

REMINDER
```
def view_report(testY,eNum,hist,y_pred_track, testYtrack):
  labelNames=['airplane', 'automobile','bird','cat','deer','dog', 'frog', 'horse', 'ship', 'truck']
  print("[INFO] evaluating network...")

```

pSplit

```
#partition
def pSplit_partition():
  pSplit=int(input('Please PROVIDE percentage of Reduction for a total of {} Training records:  '.format(len(train_X))))
  trainSel=np.random.choice(np.arange(0,len(train_X)), size=len(train_X)*pSplit//100)
  trainX, trainY=train_X[trainSel], train_y[trainSel]
  return trainX, trainY
```

to_catego
```
from keras.utils import to_categorical
def to_catego(train_y,test_y):
	# one hot encode target values

	trainY = to_categorical(train_y)
	testY = to_categorical(test_y)
	return trainY, testY
```

REMINDERs
```
eNum, hist=fit_model(model)
  print(hist.history)

        ### prereq
  !pip install keras_tqdm # please uncomment adjacent code if dependency keras_tqdm not installed yet.


    # Step_5: learning curves  

  #from matplotlib import pyplot
  print ('this a Summary of diagnostics')
  summarize_diagnostics(eNum,hist)

    #Step_6: view predictions & report & view prediction
 
  print ('this a Prediction View')
  view_prediction(model)
```


```
# PREDICTION
from sklearn.metrics import accuracy_score
y_pred  = model.predict(testXprep ).argmax(-1)
print("Test accuracy " , accuracy_score(testY_revCat , y_pred ))
```


```
for i in tqdm(np.random.choice(np.arange(0, len(testY)), size=(imgNum,))):
      # classify the object  # (I_line94-96) 
      probs = model.predict(testXprep[np.newaxis, i])  
      prediction = probs.argmax(axis=1)  
      #label = labelNames[prediction[0]]
      label=classes[prediction[0]]
```


```
# REPORT

def view_report(testY,eNum,hist,y_pred_track, testYtrack):
  labelNames=['airplane', 'automobile','bird','cat','deer','dog', 'frog', 'horse', 'ship', 'truck']
  print("[INFO] evaluating network...")

```

####**UnTrained model ```JoeBmodel```** (Prediction & REPORT)
"""



# UnTRAINED Model on PLAIN data
JoeBmodel=baseline_CNN_3VGG 
view_prediction(JoeBmodel, test_X, testY)

# UnTRAINED Model on NORMALised
JoeBmodel=baseline_CNN_3VGG 
view_prediction_NORMALised(JoeBmodel, testXprep, testY)



"""REMINDER
```
print ('this a Prediction View')
view_prediction(JMMmodel, testXprep, test_y)

```
```
def run_test_harness(JMMmodel):

  [...]

  return testXprep, test_y

```

**CHECK Harness here...!!!!**
"""

testXprep.shape, test_y.shape

testY



"""**view REPORT**"""

# show a nicely formatted classification report (learning curve)

#y_pred_track, testYtrack=view_prediction(modelJoem,test_X,testY)

def view_report(testY,eNum,hist,y_pred_track, testYtrack):
  labelNames=['airplane', 'automobile','bird','cat','deer','dog', 'frog', 'horse', 'ship', 'truck']
  print("[INFO] evaluating network...")
  #classification_report(y_true, y_pred, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')
  #y_true as groundTruth_list & y_pred as predictionList
  #print(classification_report(testY.argmax(axis=1), target_names=labelNames))
  
  print(classification_report(testYtrack,y_pred_track, target_names=labelNames)) 
  # plot the training loss and accuracy
  N=eNum # made dynamic input # N = NUM_EPOCHS 
	#plt.figure(figsize=(12,8))
	#pyplot.subplot(221)
  plt.style.use("ggplot")
  plt.figure(figsize=(10,6))
  plt.plot(np.arange(0, N), hist.history["loss"],'bo--', label="train_loss")
  plt.plot(np.arange(0, N), hist.history["val_loss"],'ro--', label="validation_loss")
  plt.plot(np.arange(0, N), hist.history["accuracy"],'b',  label="train_acc")
  plt.plot(np.arange(0, N), hist.history["val_accuracy"],'r', label="validation_acc")
  plt.title("Training Loss and Accuracy on Dataset")
  plt.xlabel("Epoch #")
  print('eNum= ',N)
  plt.xticks([i in range(N)])
  plt.ylabel("Loss/Accuracy")
  plt.legend(loc='upper right') #"lower left"
	
	#print('ticks range is ',[i for i in range(eNum+1)])
  plt.xticks([i for i in range(N+1)])
  #plt.savefig("baselineCNN3VGG_plot.png")
  plt.show()
	#print(hist.history)             # (I_line86)

print(eNum, hist.history)

#REMINDER
#y_pred_track_Joem, testYtrack_Joem=view_prediction(modelJoem,test_X,testY)
view_report(testY, eNum, hist, y_pred_track_Joem, testYtrack_Joem)

randim=int(input('Please INPUT the amount of Random images to Predict:  '))
randIndxChoice=np.random.choice(range(len(testXprep)), size=randim)
len(randIndxChoice), randIndxChoice

randIndxChoice_np_set=list(set(randIndxChoice)) #remove potential duplication
len(randIndxChoice_np_set), randIndxChoice_set

testXprep[randIndxChoice_np_set]
len(testXprep[randIndxChoice_np_set])

testY[randIndxChoice_np_set]
len(testY[randIndxChoice_np_set])

# Jay TEST HARNESS (baseline, Dropout,)
# run the test harness for evaluating a model
def run_test_harness_NORMALised(JMMmodel):
    # step_1:
     # a)**load_dataset & split** 
     # b) further partition **pSplit**  trainRecords for more epochs (if not enough time to wait...)
     # c) **to_catego** target variables to Category
  print(JMMmodel().name)
  JMMmodel().summary()
  # action-1....
  train_X, train_y, test_X, test_y=load_dataset()
  trainX, trainY=pSplit_partition(train_X, train_y)
  #trainY, testY= to_catego(train_y,test_y)
  trainY, testY= to_catego(trainY,test_y)

    # step_2: **prepare pixel-data**

  # action-2....
  trainXprep, testXprep = prep_pixels(trainX, test_X)

    # step_3: **launch the defined model** # Done as parameter
    # Step_4: **fit model**

  # action-3&4

  #model_launch(model) #done as function parameter
  
  eNum, hist=fit_model(JMMmodel, trainXprep, trainY)
  print(hist.history)

        ### prereq
  !pip install keras_tqdm # please uncomment adjacent code if dependency keras_tqdm not installed yet.


    # Step_5: learning curves  

  #from matplotlib import pyplot
  print ('\nThis a Summary of diagnostics...')
  summarize_diagnostics(JMMmodel, eNum, hist)

     #Step_6: view Prediction
             #UNcomment When Bug is Resolved... 
  print ('\This a Prediction View...')
  randim=int(input('Please INPUT the amount of Random images to Predict:  '))
  randIndxChoice=np.random.choice(range(len(testXprep)), size=randim)
  len(randIndxChoice), randIndxChoice
  randIndxChoice_np_set=list(set(randIndxChoice)) #remove potential duplication

  y_predNORM_track_slice, testYtrack_slice=view_prediction_NORMALised(JMMmodel, testXprep[randIndxChoice_np_set], testY[randIndxChoice_np_set])

    #Step_7: view Report
  print ('\nThis a Report View...')
  #Reminder# def view_report(testY,eNum,hist,y_predNORM_track, testYtrack):
  view_report(testY,eNum,hist,y_predNORM_track_slice, testYtrack_slice)    
  
  return JMMmodel, testXprep, test_y

testXprep[:10].shape

# Jay TEST HARNESS (baseline, Dropout,)
# run the test harness for evaluating a model
def run_test_harness(JMMmodel):
    # step_1:
     # a)**load_dataset & split** 
     # b) further partition **pSplit**  trainRecords for more epochs (if not enough time to wait...)
     # c) **to_catego** target variables to Category
  print(JMMmodel().name)
  JMMmodel().summary()
  # action-1....
  Jtrain_X, Jtrain_y, Jtest_X, Jtest_y=load_dataset()
  JtrainX, JtrainY=pSplit_partition(Jtrain_X, Jtrain_y)
  #trainY, testY= to_catego(train_y,test_y)
  JtrainY, JtestY= to_catego(JtrainY,Jtest_y)

    # step_2: **prepare pixel-data**

  # action-2....
  #trainXprep, testXprep = prep_pixels(trainX, test_X) # NA..as NO Normalisation made!

    # step_3: **launch the defined model** # Done as parameter
    # Step_4: **fit model**

  # action-3&4

  #model_launch(model) #done as function parameter
   #REMINDERs
  #eNum,hist=fit_model(JMMmodel, trainX, trainY)
  eNum, hist=fit_model(JMMmodel, JtrainX, JtrainY)
  print(hist.history)

        ### prereq
  !pip install keras_tqdm # please uncomment adjacent code if dependency keras_tqdm not installed yet.


    # Step_5: learning curves  

  #from matplotlib import pyplot
  print ('\nThis a Summary of diagnostics...')
  summarize_diagnostics(JMMmodel, eNum, hist)

    #Step_6: view Prediction
             #UNcomment When Bug is Resolved... 
  print ('\This a Prediction View...')  
   # y_pred_track, testYtrack=view_prediction(JMMmodel, test_X, testY)
  JpredsTrack, JtestYtrack=view_prediction(JMMmodel, Jtest_X[], JtestY)

    #Step_7: view Report
  print ('\nThis a Report View...')
 
 
  #def view_report(testY, eNum, hist, y_pred_track, testYtrack):  
  view_report(JtestY, eNum, hist,JpredsTrack, JtestYtrack)  

  
  return JMMmodel, Jtest_X, Jtest_y



#NORMALised TRAINED Model...
#Train & Test HARNESS...on Plain data
JMilto2model=baseline_CNN_3VGG
trained_JMilto2model, testXprep, test_y=run_test_harness_NORMALised(JMilto2model)
#trained_JMilto2model, test_X, test_y=run_test_harness(JMilto2model)

"""**REFERENCE**
```
# save the final model to file
from keras.datasets import cifar10
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
 
# load train and test dataset
def load_dataset():
	# load dataset
	(trainX, trainY), (testX, testY) = cifar10.load_data()
	# one hot encode target values
	trainY = to_categorical(trainY)
	testY = to_categorical(testY)
	return trainX, trainY, testX, testY
 
# scale pixels
def prep_pixels(train, test):
	# convert from integers to floats
	train_norm = train.astype('float32')
	test_norm = test.astype('float32')
	# normalize to range 0-1
	train_norm = train_norm / 255.0
	test_norm = test_norm / 255.0
	# return normalized images
	return train_norm, test_norm
 
# define cnn model
def define_model():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	[...]

	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
	return model
 
# run the test harness for evaluating a model
def run_test_harness():
	# load dataset
	trainX, trainY, testX, testY = load_dataset()
	# prepare pixel data
	trainX, testX = prep_pixels(trainX, testX)
	# define model
	model = define_model()
	# fit model
	model.fit(trainX, trainY, epochs=100, batch_size=64, verbose=0)
	# save model
	model.save('final_model.h5')
 
# entry point, run the test harness
run_test_harness()
```

```
# make a prediction for a new image.
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from keras.models import load_model
 
# load and prepare the image
def load_image(filename):
	# load the image
	img = load_img(filename, target_size=(32, 32))
	# convert to array
	img = img_to_array(img)
	# reshape into a single sample with 3 channels
	img = img.reshape(1, 32, 32, 3)
	# prepare pixel data
	img = img.astype('float32')
	img = img / 255.0
	return img
 
# load an image and predict the class
def run_example():
	# load the image
	img = load_image('sample_image.png')
	# load model
	model = load_model('final_model.h5')
	# predict the class
	result = model.predict_classes(img)
	print(result[0])
 
# entry point, run the example
run_example()


```

####**Model ```JMiltomodel```** to Train and Test
```
JMiltomodel=baseline_CNN_3VGG
testXprep, test_y=run_test_harness(JMiltomodel)
```

#**Developing an Improved Model**
"""

from keras.preprocessing.image import ImageDataGenerator

"""##**Data Augmentation (ImgGen)**
Data augmentation involves making copies of the examples in the training dataset with small random modifications.



```
# create data generator
datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)
# prepare iterator
it_train = datagen.flow(trainX, trainY, batch_size=64)

```
This can be used during training **by passing the iterator to the model.fit_generator() function** and defining the number of batches in a single epoch.

```
# fit model
steps = int(trainX.shape[0] / 64)
history = model.fit_generator(it_train, steps_per_epoch=steps, epochs=100, validation_data=(testX, testY), verbose=0)
```
***No changes to the model are required.***

The updated version of the **run_test_harness()** function to support data augmentation is listed below.

```
# set up image augmentation
datagen = ImageDataGenerator(
    rotation_range=15,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1
    #zoom_range=0.3
    )
imgDG_train_X=datagen.fit(train_X)
```
"""



# set up image augmentation
datagen = ImageDataGenerator(
    rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)
    horizontal_flip=True, # randomly flip images
    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
    height_shift_range=0.1  # randomly shift images vertically (fraction of total height)
    #fill_mode='nearest' # set mode for filling points outside the input boundaries
    )
imgDG_train_X=datagen.fit(train_X)

#imgDG_train_X.dtypes

# see example augmentation images
plt.figure(figsize=(10,8))
for X_batch, y_batch in datagen.flow(train_X, train_y, batch_size=9):
    for i in range(0, 9):
        plt.subplot(330 + 1 + i)
        plt.imshow(X_batch[i].astype(np.uint8))
    plt.show()
    break

train_X.shape

train_X.shape[0], train_X.shape[1]

X_batch.shape

def genDA_fit_model(modelJay):  
        #construct image generator
  datagen=ImageDataGenerator(width_shift_range=0.2, height_shift_range=0.2,
                             horizontal_flip=True,rotation_range=15, zoom_range=1.5,
                             fill_mode='nearest')
  it_train = datagen.flow(trainXprep, trainY, batch_size=64)# prepare iterator
  steps = int(trainX.shape[0]/64)
  try:
    eNum=int(input('Please INPUT the desired number of epochs:'))
  except ValueError:
    print('invalid entry!!...process aborted...sorry...!')
  model=modelJay()
  print(model.name)
  hist = model.fit_generator(it_train, steps_per_epoch=steps, epochs=eNum, validation_data=(test_X, testY), verbose=1)
  return eNum,hist

genDA_fit_model(baseline_CNN_3VGG)

### prereq
!pip install keras_tqdm # please uncomment adjacent code if dependency keras_tqdm not installed yet.

# run the test harness for evaluating a model
def imgDArun_test_harness(DAmodel):
    # step_1:
    # a)**load_dataset & split** 
    # aIDG) imgDataGenerator
    # b) further partition **pSplit**  trainRecords for more epochs (if not enough time to wait...)
    # c) **to_catego** target variables to Category

  train_X, train_y, test_X, test_y=load_dataset()
  trainX, trainY=pSplit_partition(train_X, train_y)
  trainY, testY= to_catego(trainY,test_y)
     
    # step_2: **prepare pixel-data**
  trainXprep, testXprep = prep_pixels(trainX,test_X) #to avoid NaN on loss

    # step_3: launch the defined model (done as this function parameter) 
 
    # step_4a: construct image generator & # step_4b: fit model
  eNumDA, histDA= genDA_fit_model(DAmodel) # ESSENTIAL to define function for the model to

  
    # Step_5: learning curves  
  #from matplotlib import pyplot
  
  print ('\nThis a Summary of diagnostics...')
  summarize_diagnostics(DAmodel, eNumDA, histDA)


    #Step_6: view Predictions
  
  print ('\This a Prediction View...')  
   # y_pred_track, testYtrack=view_prediction(JMMmodel, test_X, testY)
  DApredsTrack, DAtestYtrack=view_prediction(DAmodel, test_X, testY)
  DApredsTrack
  DAtestYtrack
 

    #Step_7: view Report
  print ('\nThis a Report View...')
  #def view_report(testY, eNum, hist, y_pred_track, testYtrack):  
  view_report(testY, eNumDA, histDA,DApredsTrack, DAtestYtrack)  

  
  return DAmodel, test_X, test_y

len(datagen.flow(train_X, train_y, batch_size=64))

"""NaN to fix at imgDArun_test_harness(baseline_CNN_3VGG)...!**DONE**

REMINDERs
```
eNum, hist=fit_model(model)
  print(hist.history)

        ### prereq
  !pip install keras_tqdm # please uncomment adjacent code if dependency keras_tqdm not installed yet.


    # Step_5: learning curves  

  #from matplotlib import pyplot
  print ('this a Summary of diagnostics')
  summarize_diagnostics(eNum,hist)

    #Step_6: view predictions & report & view prediction
 
  print ('this a Prediction View')
  view_prediction(model)
```


```
# PREDICTION
from sklearn.metrics import accuracy_score
y_pred  = model.predict(testXprep ).argmax(-1)
print("Test accuracy " , accuracy_score(testY_revCat , y_pred ))
```


```
for i in tqdm(np.random.choice(np.arange(0, len(testY)), size=(imgNum,))):
      # classify the object  # (I_line94-96) 
      probs = model.predict(testXprep[np.newaxis, i])  
      prediction = probs.argmax(axis=1)  
      #label = labelNames[prediction[0]]
      label=classes[prediction[0]]
```


```
# REPORT

def view_report(testY,eNum,hist,y_pred_track, testYtrack):
  labelNames=['airplane', 'automobile','bird','cat','deer','dog', 'frog', 'horse', 'ship', 'truck']
  print("[INFO] evaluating network...")

```
"""



"""***Reminder....

 #view_prediction(model, test_X, testY)
  #view_report(enumDA, histDA)
"""

view_prediction(baseline_CNN_3VGG, test_X, testY)



DApredsTrack, DAtestYtrack=view_prediction(baseline_CNN_3VGG, test_X, testY)

imgDArun_test_harness(baseline_CNN_3VGG)

"""###**Dropout regularisation**

"""

from keras.layers import Dropout

# define cnn model
def CNN_3VGG_dropout():
	model = Sequential(name='cnn3VGGdropout')
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.2))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.2))
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.2))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(Dropout(0.2))
	model.add(Dense(10, activation='softmax'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
	return model

CNN_3VGG_dropout().summary()



"""REMINDERs
```
eNum, hist=fit_model(model)
  print(hist.history)

        ### prereq
  !pip install keras_tqdm # please uncomment adjacent code if dependency keras_tqdm not installed yet.


    # Step_5: learning curves  

  #from matplotlib import pyplot
  print ('this a Summary of diagnostics')
  summarize_diagnostics(eNum,hist)

    #Step_6: view predictions & report & view prediction
 
  print ('this a Prediction View')
  view_prediction(model)
```


```
# PREDICTION
from sklearn.metrics import accuracy_score
y_pred  = model.predict(testXprep ).argmax(-1)
print("Test accuracy " , accuracy_score(testY_revCat , y_pred ))
```


```
for i in tqdm(np.random.choice(np.arange(0, len(testY)), size=(imgNum,))):
      # classify the object  # (I_line94-96) 
      probs = model.predict(testXprep[np.newaxis, i])  
      prediction = probs.argmax(axis=1)  
      #label = labelNames[prediction[0]]
      label=classes[prediction[0]]
```

"""

# PREDICTION
from sklearn.metrics import accuracy_score
modelJoe=CNN_3VGG_dropout()
y_predJoe  = modelJoe.predict(testXprep ).argmax(-1)
print("Test accuracy " , accuracy_score(testY_revCat , y_pred ))

def call__imgNumJoeForm(): #@title joeForm
  #@markdown Please INPUT the amount of images (no more than 24) to randomly display:
  imgNumJoe=16 #@param{type:'integer'}
  #print(imgNum)
  return imgNumJoe

call__imgNumJoeForm()

"""REMINDER
```
imgNumJoe=call__imgNumJoeForm()
print('imgNumJoe is {}'.format(imgNumJoe))
for i in tqdm(np.random.choice(np.arange(0, len(testY)), size=(imgNumJoe,))):
      # classify the object  # (I_line94-96) 
      probsJoe = modelJoe.predict(testXprep[np.newaxis, i])  
      prediction = probsJoe.argmax(axis=1)  
      #label = labelNames[prediction[0]]
      label=classes[prediction[0]]

```
"""

imgNumJoe=call__imgNumJoeForm()
print('imgNumJoe is {}'.format(imgNumJoe))
for i in tqdm(np.random.choice(np.arange(0, len(testY)), size=(imgNumJoe,))):
      # classify the object  # (I_line94-96) 
      probsJoe = modelJoe.predict(testXprep[np.newaxis, i])  
      prediction = probsJoe.argmax(axis=1)  
      #label = labelNames[prediction[0]]
      label=classes[prediction[0]]

run_test_harness(CNN_3VGG_dropout)

"""###**L2_Weight Decay regularisation**
Weight regularization or weight decay involves updating the loss function to penalize the model in proportion to the size of the model weights.

This has a regularizing effect, as larger weights result in a more complex and less stable model, whereas smaller weights are often more stable and more general.

To learn more about weight regularization, see the post:

Use Weight Regularization to Reduce Overfitting of Deep Learning Models
**We can add weight regularization** to the convolutional layers and the fully connected layers by defining the **“kernel_regularizer”** argument and specifying the type of regularization. In this case, we will use L2 weight regularization, the most common type used for neural networks and a sensible default weighting of 0.001.

The updated **baseline model with weight decay** is listed below.

https://stackoverflow.com/questions/49369472/how-to-add-0-001-l2-weight-decay-for-each-layer-in-cnn

```
net = tf.layers.conv2d(inputs=x, filters=80, kernel_size=[57, 6], strides=[1,1], padding="same", activation=tf.nn.relu, kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001))

```
"""

from keras.regularizers import l2
# define cnn model
def CNN_3VGG_w8decay(name='L2WeightDecay_CNN3VGG'):
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)))
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))
	model.add(MaxPooling2D((2, 2)))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001))) # L2 introduced
	model.add(Dense(10, activation='softmax'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
	return model

"""##HERE...."""

run_test_harness(CNN_3VGG_w8decay)

"""# **Implementing virtual adversarial training**

# Model with VAT
"""

import keras
from keras.models import * 
from keras.layers import *

#Defining VAT_CNN3VGG...

def modelJay(): 
  modelVAT= Sequential(name='VAT_CNN3VGG') # Our model  is initialized using the Sequential  API

	# first set of CONV => RELU => POOL layers
  modelVAT.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
#modelVAT.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
#modelVAT.add(MaxPooling2D((2, 2)))
	
	 # second set of CONV => RELU => POOL layers
#modelVAT.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
#modelVAT.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
#modelVAT.add(MaxPooling2D((2, 2)))
	
	 # third set of CONV => RELU => POOL layers
#modelVAT.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
#modelVAT.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
#modelVAT.add(MaxPooling2D((2, 2)))
 
 	#first (and only) set of FC (Final Coding) => RELU layers
#modelVAT.add(Flatten()) # the output of the preceding MaxPooling2D  layer and flatten it into a single vector.
#modelVAT.add(Dense(128, activation='relu', kernel_initializer='he_uniform')) # Our fully-connected layer contains 128 nodes
  modelVAT.add(Dense(10, activation='softmax')) # another fully-connected layer, but this one is special; num nodes= num classes
  return modelVAT

"""###step B_***Define the model_input*** 

the logits p_logit by applying the input to the network and the probability scores p by applying softmax activation on the logits.

```
model_input = Input((2,))
p_logit = network( model_input )
p = Activation('softmax')( p_logit )
```



"""

model_input = Input((32,32,3))
modelVAT=modelJay()
p_logit = modelVAT( model_input )
p = Activation('softmax')( p_logit )

"""###step C_***Define both compute_kdl & unit_norm functions*** 


```
def compute_kld(p_logit, q_logit):
    p = tf.nn.softmax(p_logit)
    q = tf.nn.softmax(q_logit)
    return tf.reduce_sum(p*(tf.math.log(p + 1e-16) - tf.math.log(q + 1e-16)), axis=1)

```

```
def make_unit_norm(x):
    return x/(tf.reshape(tf.sqrt(tf.reduce_sum(tf.pow(x, 2.0), axis=1)), [-1, 1]) + 1e-16)
```




"""

def compute_kld(p_logit, q_logit):
    p = tf.nn.softmax(p_logit)
    q = tf.nn.softmax(q_logit)
    return tf.reduce_sum(p*(tf.math.log(p + 1e-16) - tf.math.log(q + 1e-16)), axis=1)


def make_unit_norm(x):
    return x/(tf.reshape(tf.sqrt(tf.reduce_sum(tf.pow(x, 2.0), axis=1)), [-1, 1]) + 1e-16)

"""###step C
D_***Generate adversarial perturbation*** 
by starting with random perturbation r **and making it unit norm**
"""

#To generate the adversarial perturbation, 
r = tf.random.normal(shape=tf.shape( model_input ))
r = make_unit_norm( r )

#The output logits of the perturbed input would be p_logit_r
p_logit_r = modelVAT( model_input + 10*r  )

"""###step E_***compute KL divergence and find r_adv*** 
To get the adversarial perturbation, we need an r such that the KL-divergence is maximized. Hence take the gradient of kl with respect to r. The adversarial perturbation would be the gradient. 

!!!Attention...Error might occur if eager_execution is enabled.

[TensorFlow’s eager execution](https://r.search.yahoo.com/  2f_ylt=AwrIDKmW4ple2RkAaCJ3Bwx.;_ylu=X3oDMTByMWk2OWNtBGNvbG8DaXIyBHBvcwMyBHZ0aWQDBHNlYwNzcg--/RV=2/RE=1587172118/RO=10/RU=https%3a%2f%2ftensorflow.rstudio.com%2fguide%2ftensorflow%2feager_execution%2f/RK=2/RS=FKnnYiB0e1UpvLmyawb0aGNRzUY-) is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later. This makes it easy to get started with TensorFlow and debug models, and it reduces boilerplate as well.
Below codes are remedy:

```
import tensorflow as tf
tf.executing_eagerly()
#tf.compat.v1.disable_eager_execution() 
# uncomment code to disable eager_execution
```
"""

#Now compute the KL divergence of logits(output) from the input(p_logits) and the perturbed input(p_logits_r).
#kl = tf.reduce_mean(compute_kld( p_logit , p_logit_r ))

"""below code will have error...
```
grad_kl = tf.gradients( kl , [r ])[0]

RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.
```
if ***disabling eager_execution*** code not executed

"""

import tensorflow as tf
#tf.compat.v1.disable_eager_execution() # uncomment code to disable eager_execution

tf.executing_eagerly() # confirmation

"""**GradientTape explained**
```
Tensors can be manually watched by invoking the watch method on this context
manager.

For example, consider the function y = x * x. The gradient at x = 3.0 can
be computed as:

>>> x = tf.constant(3.0)
>>> with tf.GradientTape() as g:
...   g.watch(x)
...   y = x * x
>>> dy_dx = g.gradient(y, x) #differentiation
>>> print(dy_dx)

```
"""

#API sample
x = tf.constant(3.0)
with tf.GradientTape() as g:
  g.watch(x)
  y = x * x
  dy_dx = g.gradient(y, x)
print(dy_dx) #differentiation @ x

"""To get the adversarial perturbation, **we need an r such that the KL-divergence is maximized**. Hence take the gradient of kl with respect to r. The adversarial perturbation would be the gradient. We use the stop_gradient function because we want to keep r_vadv fixed while back-propagation."""

#grad_kl = tf.gradients( kl , [r ])[0] #RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.
import tensorflow as tf
tf.compat.v1.disable_eager_execution() # uncomment code to disable eager_execution

tf.executing_eagerly() # confirmation

#tf.compat.v1.enable_eager_execution()

tf.executing_eagerly() # confirmation

# We use the stop_gradient function because we want to keep r_vadv fixed while back-propagation.
#r_vadv = tf.stop_gradient(grad_kl)



"""#**FUTURE Tech Tasks...**

###step F_***normalise r_adv*** 
Finally, normalize the norm adversarial perturbation. We set the norm of r_vadv to a small value which is the distance we want to go along the adversarial direction.

```
r_vadv = make_unit_norm( r_vadv )/3.0
```
"""

#r_vadv = make_unit_norm( r_vadv )/3.0

"""###step G_***define loss & build the model & attach loss*** 
Now we have the adversarial perturbation **r_vadv** , for which the model gives a very large difference in outputs. 

We need to add a loss to the model which would penalize the model for having large KL-divergence with the outputs from the original inputs and the perturbed inputs.

```
p_logit_no_gradient = tf.stop_gradient(p_logit) #Reminder: p_logit = model( model_input )
p_logit_r_adv = modelVAT( model_input  + r_vadv )
vat_loss = tf.reduce_mean(compute_kld( p_logit_no_gradient, p_logit_r_adv ))

# Finally, build the model and attach the vat_loss .

model_vat = Model(model_input , p ) #Reminder: model=
model_vat.add_loss( vat_loss   )

model_vat.compile( 'sgd' ,  'categorical_crossentropy'  ,  metrics=['accuracy'])

model_vat.metrics_names.append('vat_loss')
model_vat.metrics.append( vat_loss )
```

"""

#with tf.Graph().as_default():
#modelVAT=modelJay()
#p_logit_no_gradient = tf.stop_gradient(p_logit) #Reminder: p_logit = model( model_input )
#p_logit_r_adv = modelVAT( model_input  + r_vadv )
#vat_loss = tf.reduce_mean(compute_kld( p_logit_no_gradient, p_logit_r_adv ))

"""```
#DRAFT Construct and compile an instance of CustomModel
#inputs = keras.Input(shape=(32,)) #REMINDER model_input = Input((32,32,3))
outputs = keras.layers.Dense(10)(model_input) #outputs = keras.layers.Dense(1)(inputs)
model = Model(model_input, outputs)
#model.compile(optimizer="adam", loss="mse", metrics=["mae"])
 
# Just use `fit` as usual
x = np.random.random((1000, 32))
y = np.random.random((1000, 1))
model.fit(x, y, epochs=3)
```

## Let’s train the model by calling the fit function....
"""



"""####step2: **Data Prepa**"""

# step_1:
     # a)**load_dataset & split** 
     # b) further partition **pSplit**  trainRecords for more epochs (if not enough time to wait...)
     # c) **to_catego** target variables to Category
print(modelVAT.name)
# summarize loaded dataset
print('\nLoaded dataset SUMMARY')
train_X_vat, train_y_vat, test_X_vat, test_y_vat=load_dataset()
print('\nvariable renamed as ~_vat')
print('train_X_vat=%s, train_y_vat=%s' % (train_X_vat.shape, train_y_vat.shape))
print('test_X_vat=%s, test_y_vat=%s' % (test_X_vat.shape, test_y_vat.shape))
print() 
vat_trainX, vat_trainY=pSplit_partition(train_X_vat, train_y_vat)
# summarize training pSplit partition
print('\ntraining pSplit partition SUMMARY')
print('vat_trainX=%s, vat_trainY=%s' % (vat_trainX.shape, vat_trainY.shape))

vat_trainY, vat_testY= to_catego(vat_trainY,test_y_vat)
# summarize target2category
print('\ntarget2category SUMMARY')
print('vat_trainY=%s, vat_testY=%s' % (vat_trainY.shape, vat_testY.shape))

# step_2: **prepare pixel-data**
vat_trainX_prep, test_X_vat_prep = prep_pixels(vat_trainX,test_X_vat)
# summarize target2category
print('\npixel-data prepa summary')
print('vat_trainX_prep=%s, test_X_vat_prep=%s' % (vat_trainX_prep.shape, test_X_vat_prep.shape))

# step_3: **launch the defined model** # not require as not a defined function 
# Step_4: **fit model**

vat_trainX_prep.shape

vtXp_level1=np.concatenate(vat_trainX_prep) #1st level of concatenation
vtXp_level1.shape

vtXp_level2=np.concatenate(vtXp_level1) #2nd level of concatenation
vtXp_level2.shape

vtXp_level3=np.concatenate(vtXp_level2) #3rd level of concatenation
vtXp_level3.shape

vtY_level1=np.concatenate(vat_trainY) #1st level of concatenation
vtY_level1.shape

#vat_trainX_prep[0]

vat_trainY.shape

vat_trainY[0]

vat_trainY[0].argmax(-1)

"""```
	# first set of CONV => RELU => POOL layers
modelVAT.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))

modelVAT.add(Dense(10, activation='softmax'))
```

###step_4 fit **model_vat & Predict**
"""

# Finally, build the model and attach the vat_loss .
inputs =keras.Input(shape=(32,32,3))
#x = keras.layers.Dense(64, activation="relu", name="dense_1")(inputs) #REMINDER model_input = Input((32,32,3))

x1 = keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(inputs)
#x1 = keras.layers.Dense(64, activation="relu", name="dense_2")(x1)
x1 = keras.layers.GlobalMaxPooling2D()(x1)

outputs = keras.layers.Dense(10,activation='softmax')(x1)

model_vat = keras.Model(inputs , outputs ) # revised model 

model_vat.add_loss('vat_loss')

model_vat.compile( 'sgd' ,  'categorical_crossentropy'  ,  metrics=['accuracy'])

#We return a dictionary mapping metric names (including the loss) to their current value.
#(jayRead https://keras.io/guides/customizing_what_happens_in_fit/  )
model_vat.metrics_names.append('vat_loss')
model_vat.metrics.append( vat_loss )

print('inputs Shape: {}'.format(inputs.shape))
print('outputs Shape: {}'.format(outputs.shape))

#below code is to avoid...#InvalidArgumentError: 
#You must feed a value for placeholder tensor 'input_2' with dtype float and shape [?,32,32,3]
	# [[{{node input_2}}]]
with tf.Graph().as_default():
  model_vat.fit(vat_trainX_prep , vat_trainY) 
#model_vat.fit(vat_trainX_prep[:1] , vat_trainY[:1])

vat_trainX_prep.shape

vat_trainY.shape

"""```
print("Fit model on training data")
history = model.fit(
    x_train,
    y_train,
    batch_size=64,
    epochs=2,
    # We pass some validation for
    # monitoring validation loss and metrics
    # at the end of each epoch
    validation_data=(x_val, y_val),
)
```

```
model_vat = Model(model_input , p ) # revised model 
model_vat.add_loss( vat_loss   )

model_vat.compile( 'sgd' ,  'categorical_crossentropy'  ,  metrics=['accuracy'])

import numpy as np
# We return a dictionary mapping metric names (including the loss) to their current value.
model_vat.metrics_names.append('vat_loss')
model_vat.metrics.append( vat_loss )
```

```
model_vat.fit(  np.concatenate([train]*10000) , np.concatenate([Y_train_cat]*10000)  ) # to flatten records

y_pred  = model_vat.predict( X_test ).argmax(-1)
print( "Test accruracy " , accuracy_score(Y_test , y_pred  ))
```
"""

y_pred  = model_vat.predict( VATtestXprep ).argmax(-1)
print( "Test accuracy " , accuracy_score(VATtestY , y_pred  ))

try:
  eNum=int(input('Please INPUT the desired number of epochs:'))
except ValueError:
  print('invalid entry!!...process aborted...sorry...!')
    
hist = model.fit(trainXprep, trainY, epochs=eNum, batch_size=64, validation_split=0.3, verbose=1,)
# validation_split=0.1means we use 10% of training data as the validation data
# epochs is the number of training loops we will do. 
# one epoch will expose all of our training data once to the network. 
# more epochs means the network will know better about our data.
# and the result is...

model_vat.fit()

"""###REMINDER...

```

def baseline_CNN_3VGG():

	model = Sequential(name='baselineCNN3VGG') # Our model  is initialized using the Sequential  API
  
	# first set of CONV => RELU => POOL layers
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	
	 # second set of CONV => RELU => POOL layers
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
	
	 # third set of CONV => RELU => POOL layers
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(MaxPooling2D((2, 2)))
 
 	#first (and only) set of FC (Final Coding) => RELU layers
 	model.add(Flatten()) # the output of the preceding MaxPooling2D  layer and flatten it into a single vector.
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform')) # Our fully-connected layer contains 128 nodes
	model.add(Dense(10, activation='softmax')) # another fully-connected layer, but this one is special; num nodes= num classes
  
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

	return model
```


"""

import keras
from keras.models import*
from keras.layers import*


modelVAT = Sequential(name='VAT_CNN3VGG') # Our model  is initialized using the Sequential  API
  
	# first set of CONV => RELU => POOL layers
modelVAT.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
modelVAT.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
modelVAT.add(MaxPooling2D((2, 2)))
	
	 # second set of CONV => RELU => POOL layers
modelVAT.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
modelVAT.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
modelVAT.add(MaxPooling2D((2, 2)))
	
	 # third set of CONV => RELU => POOL layers
modelVAT.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
modelVAT.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
modelVAT.add(MaxPooling2D((2, 2)))
 
 	#first (and only) set of FC (Final Coding) => RELU layers
modelVAT.add(Flatten()) # the output of the preceding MaxPooling2D  layer and flatten it into a single vector.
modelVAT.add(Dense(128, activation='relu', kernel_initializer='he_uniform')) # Our fully-connected layer contains 128 nodes
modelVAT.add(Dense(10, activation='softmax')) # another fully-connected layer, but this one is special; num nodes= num classes
  

# Define the model_input , the logits p_logit
#  by applying the input to the network and the probability scores p by applying softmax activation on the logits.
model_input = Input((32,32,3))
p_logit = modelVAT( model_input )
p = Activation('softmax')( p_logit )

#To generate the adversarial perturbation, 
r = tf.random.normal(shape=tf.shape( model_input ))
r = make_unit_norm( r )

#The output logits of the perturbed input would be p_logit_r
p_logit_r = modelVAT( model_input + 10*r  )

import tensorflow as tf
tf.compat.v1.disable_eager_execution() # uncomment code to disable eager_execution

#Now compute the KL divergence of logits(output) from the input(p_logits) and the perturbed input(p_logits_r).
kl = tf.reduce_mean(compute_kld( p_logit , p_logit_r ))
grad_kl = tf.gradients( kl , [r ])[0]


# We use the stop_gradient function because we want to keep r_vadv fixed while back-propagation.
r_vadv = tf.stop_gradient(grad_kl)

r_vadv = make_unit_norm( r_vadv )/3.0

p_logit_no_gradient = tf.stop_gradient(p_logit) #Reminder: p_logit = model( model_input )
p_logit_r_adv = modelVAT( model_input  + r_vadv )
vat_loss = tf.reduce_mean(compute_kld( p_logit_no_gradient, p_logit_r_adv ))

# Finally, build the model and attach the vat_loss .

model_vat = Model(model_input , p )
model_vat.add_loss( vat_loss   )

# compile model
	#opt = SGD(lr=0.001, momentum=0.9)
	#model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])

model_vat.compile( 'sgd' ,  'categorical_crossentropy'  ,  metrics=['accuracy'])

model_vat.metrics_names.append('vat_loss')
model_vat.metrics.append( vat_loss )



# run the test harness for evaluating a model
def run_B_test_harness():
	# load dataset
	trainX, trainY, testX, testY = load_dataset()
	# prepare pixel data
	trainX, testX = prep_pixels(trainX, testX)
	# define model
	model = define_model() #to replace with chosen model
	# fit model
	history = model.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0)
	
	# learning curves
	summarize_diagnostics(history)

# entry point, run the test harness
run_test_harness()





"""##HYBRID Method for Further Improvement

###**Dropout and VAT (Data Augmentation) and Batch Normalization**
We can expand upon the previous example in a few ways.

First, we can increase the number of training epochs from 200 to 400, to give the model more of an opportunity to improve.

Next, we can add batch normalization in an effort to stabilize the learning and perhaps accelerate the learning process. To offset this acceleration, we can increase the regularization by changing the dropout from a fixed pattern to an increasing pattern.

The updated model definition is listed below.
"""

# define cnn model
def CNN_Hybrid():
	model = Sequential()
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
	model.add(BatchNormalization())
	model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(BatchNormalization())
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.2))
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(BatchNormalization())
	model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(BatchNormalization())
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.3))
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(BatchNormalization())
	model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
	model.add(BatchNormalization())
	model.add(MaxPooling2D((2, 2)))
	model.add(Dropout(0.4))
	model.add(Flatten())
	model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
	model.add(BatchNormalization())
	model.add(Dropout(0.5))
	model.add(Dense(10, activation='softmax'))
	# compile model
	opt = SGD(lr=0.001, momentum=0.9)
	model.compile(optimizer=opt, loss=-tf.reduce_sum(y_*tf.log(y_conv + 1e-10)), metrics=['accuracy']) #'categorical_crossentropy'
	return model

"""Running the model in the test harness prints the classification accuracy on the test dataset.

#SOURCE
"""

plot_model_predictions(baseline)

:
# build and compile the model  (roughly following the VGG paper)

#reg=l2(1e-4)   # L2 or "ridge" regularisation
reg=None
num_filters=32
ac='relu'
adm=Adam(lr=0.001,decay=0, beta_1=0.9, beta_2=0.999, epsilon=1e-08)
opt=adm
drop_dense=0.5
drop_conv=0

model = Sequential()

model.add(Conv2D(num_filters, (3, 3), activation=ac, kernel_regularizer=reg, input_shape=(img_rows, img_cols, channels),padding='same'))
model.add(BatchNormalization(axis=-1))
model.add(Conv2D(num_filters, (3, 3), activation=ac,kernel_regularizer=reg,padding='same'))
model.add(BatchNormalization(axis=-1))
model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 16x16x3xnum_filters
model.add(Dropout(drop_conv))

model.add(Conv2D(2*num_filters, (3, 3), activation=ac,kernel_regularizer=reg,padding='same'))
model.add(BatchNormalization(axis=-1))
model.add(Conv2D(2*num_filters, (3, 3), activation=ac,kernel_regularizer=reg,padding='same'))
model.add(BatchNormalization(axis=-1))
model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 8x8x3x(2*num_filters)
model.add(Dropout(drop_conv))

model.add(Conv2D(4*num_filters, (3, 3), activation=ac,kernel_regularizer=reg,padding='same'))
model.add(BatchNormalization(axis=-1))
model.add(Conv2D(4*num_filters, (3, 3), activation=ac,kernel_regularizer=reg,padding='same'))
model.add(BatchNormalization(axis=-1))
model.add(MaxPooling2D(pool_size=(2, 2)))   # reduces to 4x4x3x(4*num_filters)
model.add(Dropout(drop_conv))

model.add(Flatten())
model.add(Dense(512, activation=ac,kernel_regularizer=reg))
model.add(BatchNormalization())
model.add(Dropout(drop_dense))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=opt)

model.summary()

# training without augmentation
history=model.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test))

#training accuracy without dropout
train_acc=model.evaluate(x_train,y_train,batch_size=128)
train_acc

plothist(history)